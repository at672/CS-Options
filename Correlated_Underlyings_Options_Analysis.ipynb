{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Underlyings and Their effect on Option Payoffs\n",
    "\n",
    "In this exercise we will analyze three types of options with different payoff structures and determine how differences in correlation between the underlying affect the payoff."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider two stocks, determined by their respective processes $\\{(S_1(t), S_2(t)) : t \\geq 0\\}$ be geometric brownian motions with drift vector $\\boldsymbol{\\mu}$ and covariance matrix $\\boldsymbol{\\Sigma}$.\n",
    "\n",
    "In this example, let us assume that $\\boldsymbol{\\mu} = [r, r]^T$ and, since all covariance matricies are real and positive semi-definite, $\\boldsymbol{\\Sigma}$ can be decomposed as $\\boldsymbol{\\Sigma} = AA^T$\n",
    "\n",
    "If we take $A$ to be a lower triangular matrix, then this is called a Cholesky decomposition. However, I am going to do something simpler. Since this problem only involves two variables, I will set $A = \\begin{pmatrix}\n",
    "1 & c\\\\\n",
    "c & 1\n",
    "\\end{pmatrix} $ instead of $A = \\begin{pmatrix}\n",
    "1 & 0\\\\\n",
    "c & 1\n",
    "\\end{pmatrix} $\n",
    "\n",
    "The second formulation is what would be used for a cholesky decomposition.\n",
    "\n",
    "You can verify for yourself that if we take the first definition of $A$, then the variances of each process will be equal, whereas in a cholesky decomposition, that is not necessarily true.\n",
    "\n",
    "I will choose multiple values of $c$ to control the amount of covariance that each stock has with each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the options, we will test three options. They and their payoffs are:\n",
    "\n",
    "1. Spread option: $ Y_1 = \\mathbb{E}^\\mathbb{Q} \\left[ e^{-r(T-t)}\\max(S_1(T) - S_2(T) - K, 0)  | \\mathcal{F}_t \\right] $\n",
    "2. Basket option: $ Y_1 = \\mathbb{E}^\\mathbb{Q} \\left[ e^{-r(T-t)}\\max(S_1(T) + S_2(T) - K, 0)  | \\mathcal{F}_t \\right] $\n",
    "3. Outperformance option: $ Y_1 = \\mathbb{E}^\\mathbb{Q} \\left[ e^{-r(T-t)}\\max[\\max(S_1(T) , S_2(T)) - K)]  | \\mathcal{F}_t \\right] $\n",
    "\n",
    "\n",
    "For this example, we will choose parameters as follows\n",
    "\n",
    "$S_1(0) = S_2(0) = 1, K = 2, r = 0.05, T = 1$\n",
    "$c = -0.5, 0, 0.5$\n",
    "We will use 20,000 monte carlo iterations and comment on our findings. Speaking of which, before we run any monte carlo simulations, simply by looking at the payoffs, we expect that when $S_1$ and $S_2$ diverge significantly, we expect a high payoff on the spread and a low payoff on the basket. Thus, when we believe stocks are negatively correlated, we prefer the spread option. Similarly, we expect that when $S_1$ and $S_2$ are highly correlated, we expect a high payoff on the basket and a low payoff on the spread. Thus, when we believe stocks are positively correlated, we prefer the basket option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GBM parameters\n",
    "r = 0.05\n",
    "mu = np.array([r, r])\n",
    "S0_1 = 1\n",
    "S0_2 = 1\n",
    "\n",
    "# Other parameters\n",
    "K = 2; # strike\n",
    "\n",
    "c_values = [-0.5, -0.25, 0, 0.25, 0.5]\n",
    "Sigma_values = [0, 0, 0, 0, 0]\n",
    "\n",
    "names = ['spread', 'basket', 'outperformance']\n",
    "#cart_prod = [(a,b) for a in c_values for b in names]\n",
    "#results = {key: None for key in c_values}\n",
    "results = {}\n",
    "\n",
    "#Generate 20000 sample paths\n",
    "#Note that we are generating only one time point worth of brownians. That is, in our simulation, we have a value at T = 0 and a value at T = 1, from the random variable draw\n",
    "#If we want multiple time points, we will need another dimension added to this draw\n",
    "\n",
    "np.random.seed(seed=13818376)\n",
    "\n",
    "reps = 20000 # of replications (sample paths)\n",
    "T = 1\n",
    "\n",
    "#standard normal RVs for W(t)\n",
    "Z = sp.norm.rvs(loc = 0, scale = np.sqrt(T), size = (reps, 2))\n",
    "\n",
    "#WE apply the common random numbers scheme to make sure we analyze only the affects of changing the parameter c\n",
    "for i in range(0, len(c_values)):\n",
    "    c = c_values[i]\n",
    "    A = np.array([[1,c],[c,1]])\n",
    "    Sigma_values[i] = np.matmul(A, np.transpose(A))\n",
    "    Sigma = Sigma_values[i]\n",
    "\n",
    "    ST_1 = S0_1*np.exp((mu[0] - Sigma[0,0]/2)*T + A[0,0]*Z[:,0] + A[0,1]*Z[:,1])\n",
    "    ST_2 = S0_2*np.exp((mu[1] - Sigma[1,1]/2)*T + A[1,0]*Z[:,0] + A[1,1]*Z[:,1])\n",
    "\n",
    "    #Confidence level critical value for 95% interval\n",
    "    z_alpha2 = 1.96\n",
    "\n",
    "    payoffs_spread = np.exp(-r*T)*np.maximum(ST_1 - ST_2 - K, 0)\n",
    "    p_s_mean = np.mean(payoffs_spread)\n",
    "    p_s_std = np.std(payoffs_spread)\n",
    "    p_s_lb = p_s_mean - z_alpha2*p_s_std/np.sqrt(reps)\n",
    "    p_s_ub = p_s_mean + z_alpha2*p_s_std/np.sqrt(reps)\n",
    "    results[ (c, 'spread')] = [p_s_mean, p_s_std, p_s_lb, p_s_ub]\n",
    "\n",
    "    payoffs_basket = np.exp(-r*T)*np.maximum(ST_1 + ST_2 - K, 0);\n",
    "    p_b_mean = np.mean(payoffs_basket);\n",
    "    p_b_std = np.std(payoffs_basket);\n",
    "    p_b_lb = p_b_mean - z_alpha2*p_b_std/np.sqrt(reps)\n",
    "    p_b_ub = p_b_mean + z_alpha2*p_b_std/np.sqrt(reps)\n",
    "    results[ (c, 'basket')] = [p_b_mean, p_b_std, p_b_lb, p_b_ub]\n",
    "\n",
    "    payoffs_outperform = np.exp(-r*T)*np.maximum(np.maximum(ST_1, ST_2) - K, 0)\n",
    "    p_o_mean = np.mean(payoffs_outperform)\n",
    "    p_o_std = np.std(payoffs_outperform)\n",
    "    p_o_lb = p_o_mean - z_alpha2*p_o_std/np.sqrt(reps)\n",
    "    p_o_ub = p_o_mean + z_alpha2*p_o_std/np.sqrt(reps)\n",
    "    results[ (c, 'outperformance')] = [p_o_mean, p_o_std, p_o_lb, p_o_ub]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">-0.50</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-0.25</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.00</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.25</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>spread</th>\n",
       "      <th>basket</th>\n",
       "      <th>outperformance</th>\n",
       "      <th>spread</th>\n",
       "      <th>basket</th>\n",
       "      <th>outperformance</th>\n",
       "      <th>spread</th>\n",
       "      <th>basket</th>\n",
       "      <th>outperformance</th>\n",
       "      <th>spread</th>\n",
       "      <th>basket</th>\n",
       "      <th>outperformance</th>\n",
       "      <th>spread</th>\n",
       "      <th>basket</th>\n",
       "      <th>outperformance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.2376</td>\n",
       "      <td>0.5649</td>\n",
       "      <td>0.5086</td>\n",
       "      <td>0.1828</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.6344</td>\n",
       "      <td>0.3996</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.3883</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.3869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StDev</th>\n",
       "      <td>1.3737</td>\n",
       "      <td>1.8247</td>\n",
       "      <td>1.8071</td>\n",
       "      <td>1.0813</td>\n",
       "      <td>1.5458</td>\n",
       "      <td>1.4684</td>\n",
       "      <td>0.8843</td>\n",
       "      <td>1.5939</td>\n",
       "      <td>1.3392</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>1.9615</td>\n",
       "      <td>1.3911</td>\n",
       "      <td>0.5722</td>\n",
       "      <td>2.5901</td>\n",
       "      <td>1.5707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CI Lower Bound</th>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.5485</td>\n",
       "      <td>0.4147</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.6123</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>0.7048</td>\n",
       "      <td>0.3691</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.3651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CI Upper Bound</th>\n",
       "      <td>0.2567</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>0.5336</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.4554</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.4181</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.7592</td>\n",
       "      <td>0.4076</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.8815</td>\n",
       "      <td>0.4087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 -0.50                          -0.25                         \\\n",
       "                spread  basket outperformance  spread  basket outperformance   \n",
       "Mean            0.2376  0.5649         0.5086  0.1828  0.5699         0.4350   \n",
       "StDev           1.3737  1.8247         1.8071  1.0813  1.5458         1.4684   \n",
       "CI Lower Bound  0.2186  0.5396         0.4835  0.1678  0.5485         0.4147   \n",
       "CI Upper Bound  0.2567  0.5902         0.5336  0.1978  0.5914         0.4554   \n",
       "\n",
       "                  0.00                           0.25                         \\\n",
       "                spread  basket outperformance  spread  basket outperformance   \n",
       "Mean            0.1354  0.6344         0.3996  0.0928  0.7320         0.3883   \n",
       "StDev           0.8843  1.5939         1.3392  0.7360  1.9615         1.3911   \n",
       "CI Lower Bound  0.1231  0.6123         0.3810  0.0826  0.7048         0.3691   \n",
       "CI Upper Bound  0.1477  0.6565         0.4181  0.1030  0.7592         0.4076   \n",
       "\n",
       "                  0.50                         \n",
       "                spread  basket outperformance  \n",
       "Mean            0.0539  0.8457         0.3869  \n",
       "StDev           0.5722  2.5901         1.5707  \n",
       "CI Lower Bound  0.0460  0.8098         0.3651  \n",
       "CI Upper Bound  0.0619  0.8815         0.4087  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "asdf = pd.DataFrame(data = results)\n",
    "asdf.rename(index={0: \"Mean\", 1: \"StDev\", 2: \"CI Lower Bound\", 3: \"CI Upper Bound\"})\n",
    "\n",
    "#Output = pd.DataFrame(data = asdf.transpose(), columns = ['Mean', 'StDev', 'CI Lower Bound', 'CI Upper Bound'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice a few things.\n",
    "\n",
    "First, at the very left, when the correlation is the most negative, we see that the spread option is worth the most, at 0.2376. But as we increase the correlation (as we scan from the left to right on the top most row), the value of the spread option decreases, monotonically.\n",
    "\n",
    "This is consistent with our intuition.\n",
    "\n",
    "Similarly, at the most negative correlation, the basket option is worth the least, but it increases in value monotonically as we increase the correlation.\n",
    "\n",
    "The outperformance option si tricky to understand. It has the highest expected payoff when the assets are negatively correlated. We can think of it this way, if the assets are positively correlated, then when we take $\\max(S_1, S_2)$, if the values were going to be high to begin with, it doesn't matter which one is higher, so long as one clears the strike. If the values were low to begin with, then it wouldn't matter because the payoff would have been zero. However, when the correlation is strongly negative, then even if one path does not clear the strike price, the other path could. This phenomenon, over enough paths, manifests in the higher valuation.\n",
    "\n",
    "Finally, we see that across the board, the Basket option is more valuable than the outpeformance option, which is more valuable than the spread option."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
