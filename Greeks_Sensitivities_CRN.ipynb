{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Option Greeks\n",
    "\n",
    "This notebook shows how to calculate Option Greeks using the pathwise estimation method as well as the likelihood ratio method.\n",
    "\n",
    "While understanding how to price options is important, it is equally if not more important to understand how the price of an option changes with respect to its underlying inputs.\n",
    "\n",
    "Recall that the price of an option, under a Black Scholes framework, is dependent on five parameters:\n",
    "\n",
    "1. The stock price\n",
    "2. The strike price\n",
    "3. The time until maturity\n",
    "4. The volatility of the stock\n",
    "5. The interest rate\n",
    "\n",
    "Under a Black Scholes framework, we can compute the partial derivatives with respect to four of these inputs (since strike price is a constant, it does not make sense to compute a derivative with respect to it.) These are commonly referred to as the Greeks, as the names of (some of) these partial derivatives are based on Greek letters. The ones that are not are named to \"sound like\" Greek letters, but no actual greek letter exists.\n",
    "\n",
    "### Black Scholes\n",
    "\n",
    "The Greeks can be computed analytically as shown above. We start with the analytical form of the BS equation:\n",
    "\n",
    "$ C(S_t, t) $ is the call price and $P(S_t, t) $ is the put price. I will also denote $V$ as a generic option value function, for either a Call or a Put.\n",
    "\n",
    "$ \\begin{aligned}C(S_{t},t)&=N(d_{1})S_{t}-N(d_{2})PV(K)\\\\d_{1}&={\\frac {1}{\\sigma {\\sqrt {T-t}}}}\\left[\\ln \\left({\\frac {S_{t}}{K}}\\right)+\\left(r+{\\frac {\\sigma ^{2}}{2}}\\right)(T-t)\\right]\\\\d_{2}&=d_{1}-\\sigma {\\sqrt {T-t}}\\\\PV(K)&=Ke^{-r(T-t)}\\end{aligned}  $\n",
    "\n",
    " The price of a corresponding put option based on putâ€“call parity is:\n",
    " \n",
    "$ \\begin{aligned}P(S_{t},t)&=Ke^{-r(T-t)}-S_{t}+C(S_{t},t)\\\\&=N(-d_{2})Ke^{-r(T-t)}-N(-d_{1})S_{t}\\end{aligned} $\n",
    "\n",
    "\n",
    "### The Greeks (Definitions)\n",
    "\n",
    "Analytical computations/proofs may be added later, but can be found from many reference books.\n",
    "\n",
    "#### Delta\n",
    "\n",
    "Delta is defined as the partial derivative of the option value with respect to the underlying.\n",
    "\n",
    "$Delta = \\Delta = \\frac{\\partial V}{\\partial S} $\n",
    "\n",
    "#### Gamma\n",
    "\n",
    "Gamma is defined as the partial derivative of an option's delta with respect to the underlying. Thus it is the second derivative of the option value with respect to the underlying.\n",
    "\n",
    "$Gamma = \\Gamma = \\frac{\\partial \\Delta}{\\partial S}  = \\frac{\\partial ^2 V}{\\partial S^2}$\n",
    "\n",
    "#### Vega\n",
    "\n",
    "Vega is defined as the partial derivative of the option price with respect to the volatility.\n",
    "\n",
    "$Vega = \\mathcal{V} = \\frac{\\partial V}{\\partial \\sigma} $\n",
    "\n",
    "#### Theta\n",
    "\n",
    "Theta is defined as the partial derivative of the option price with respect to time.\n",
    "\n",
    "$Theta = \\Theta = \\frac{\\partial V}{\\partial t} $\n",
    "\n",
    "Note that sometimes it is defined as $-\\frac{\\partial V}{\\partial \\tau} $. Since $\\tau = T - t$, these derivatives are consistent. (Recall that $T$ is the maturity time, $t$ is the variable of time, and $\\tau$ measures the time remaining until maturity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Less important Greeks:\n",
    "\n",
    "#### Rho\n",
    "\n",
    "Rho is defined as the partial derivative of the option value with respect to the (risk free) interest rate.\n",
    "$Rho = \\rho = \\frac{ \\partial V}{\\partial r} $\n",
    "\n",
    "\n",
    "#### Vomma\n",
    "\n",
    "Vomma is the partial derivative of an option's Vega with respect to volatility. Thus it is the second order partial derivative of the option price function with respect to volatility.\n",
    "\n",
    "$Vanna = \\frac{ \\partial \\mathcal{V}}{\\partial \\sigma} = \\frac{\\partial ^2 V}{\\partial \\sigma^2}$\n",
    "\n",
    "#### Vanna\n",
    "\n",
    "Vanna is the partial derviative of the Vega with respect to the spot price, or the partial derivative of the Delta with respect to volatility. It is thus the 2nd order cross partial of the option value with respect to the spot price and the volatility.\n",
    "\n",
    "$Vanna = \\frac{ \\partial \\Delta}{\\partial \\sigma} = \\frac{\\partial ^2 V}{\\partial S \\partial \\sigma}$\n",
    "\n",
    "#### Veta\n",
    "Veta is the partial derviative of the Vega with respect to time, or the partial derivative of the Theta with respect to volatility. It is thus the 2nd order cross partial of the option value with respect to the time and the volatility. It measures how the Vega is changing with the passage of time\n",
    "$Vanna = \\frac{ \\partial \\mathcal{V}}{\\partial \\tau} = \\frac{\\partial ^2 V}{\\partial \\tau \\partial \\sigma}$\n",
    "\n",
    "\n",
    "#### Charm\n",
    "\n",
    "$Vanna = \\frac{ \\partial \\mathcal{V}}{\\partial \\sigma} = \\frac{\\partial ^2 V}{\\partial \\sigma^2}$\n",
    "\n",
    "\n",
    "Reference: https://en.wikipedia.org/wiki/Greeks_(finance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finite Differencing\n",
    "\n",
    "Finite differencing is the simplest way to compute derivatives. It is a numerical estimation method for computing the derivative of a function. It can be applied to many \"well behaving\" functions. We will focus on two, the forward finite difference, and the central finite difference.\n",
    "\n",
    "Let use define the following variables:\n",
    " $n$ is the number of replications/simulations,\n",
    " $h$ is the increment size, or the small perturbation,\n",
    "$Y_i(\\theta)$ is a random variable that is dependent on the parameter $\\theta$. Note that $Y_i's$ are i.i.d.\n",
    "\n",
    "$\\alpha (\\theta) = \\mathbb{E}[Y(\\theta)]$\n",
    "\n",
    "The quantity we are interested in estimating is $\\alpha ^\\prime (\\theta)$, i.e. the derivative of $\\alpha$.\n",
    "\n",
    "In the context of options, $Y(\\theta)$ will usually be the discounted payoff of an option, $\\alpha$ the price of the option, and $\\theta$ the individual variable we are singling out to perform sensitivity analysis on. If we take $\\theta$ to be $S$, we will be estimating the delta. If we take $\\theta$ to be $\\sigma$, then we will be estimating the Vega. Note that the $\\theta$ here is simply to define the equations. This is **not** the options Theta.\n",
    "\n",
    "The forward finite difference is defined as:\n",
    "\n",
    "$\\Delta_F(n,h) = \\frac{\\bar{Y}_n(\\theta+h) - \\bar{Y}_n(\\theta)}{h}$\n",
    "\n",
    "Now let's take the expectation of this. On the right hand side, we have, by the linearity property of expectations:\n",
    "\n",
    "$ \\frac{\\mathbb{E}[\\bar{Y}_n(\\theta+h)] - \\mathbb{E}[\\bar{Y}_n(\\theta)]}{h}$\n",
    "\n",
    "But based on our definition above, we can simply rewrite this as:\n",
    "\n",
    "$\\frac{\\alpha(\\theta+h) - \\alpha(\\theta)}{h}$\n",
    "\n",
    "\n",
    "We know from the Taylor series expansion, that if $\\alpha$ is a twice continuously differentiable function, (which it is in our case), then\n",
    "\n",
    "$\\alpha(\\theta + h) = \\alpha(\\theta) + \\alpha ^\\prime(\\theta)h + \\frac{1}{2} \\alpha ^{\\prime\\prime}(\\xi)h^2$\n",
    "\n",
    "where $\\xi$ is a small value that lies in $(\\theta, \\theta + h)$\n",
    "\n",
    "Therefore, if we plug this result in to our equation for the expectation, we have:\n",
    "\n",
    "$\\mathbb{E}[\\Delta_F(n,h)] = \\alpha ^\\prime(\\theta) + \\frac{1}{2} \\alpha ^{\\prime\\prime}(\\xi)h$\n",
    "\n",
    "But recall our goal was to compute $\\alpha ^\\prime(\\theta)$. Since this is not our expected value, our estimator has a bias of $\\frac{1}{2} \\alpha ^{\\prime\\prime}(\\xi)h = \\frac{1}{2} \\alpha ^{\\prime\\prime}(\\theta)h + o(h)$ where $o(h)$ is notation for a deterministic function $\\psi$ with the property that $\\lim_{h \\to 0} \\frac{\\psi}{h} \\to 0$\n",
    "\n",
    "The important thing to know is that the forward finite difference is biased and the bias is proprotional to the value of the second derivative. For example, if we compute a forward finite difference for an Option's Delta, it will be biased in proportion to its Gamma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can use the central finite difference, defined as:\n",
    "\n",
    "$\\Delta_C(n,h) = \\frac{\\bar{Y}_n(\\theta+h) - \\bar{Y}_n(\\theta - h)}{2h}$\n",
    "\n",
    "Using results from above, we can easily replace the \"+\" with a \"-\" to compute the 2nd term in this expression, and then easily show that:\n",
    "\n",
    "$\\mathbb{E}[\\Delta_C(n,h)] = \\frac{\\alpha(\\theta + h) + \\alpha(\\theta - h)}{2h} = (2\\alpha^\\prime(\\theta)h)/(2h) = \\alpha ^\\prime(\\theta) + o(h)$.\n",
    "\n",
    "Just as above, the $o(h)$ term can be ignored. For all intents and purposes, the central finite difference provides us with an unbiased estimator.\n",
    "\n",
    "Note the tradeoff: We always simulate at the value $\\theta$. With forward finite differences, we perform simply one additional simulation, at $\\theta + h$. With central finite differences, we perform a total of two additional simulations. \n",
    "\n",
    "Usually, the additional simulation is worth it as we value the reduction in bias.\n",
    "\n",
    "#### Variance of Finite Differences\n",
    "\n",
    "I have ommitted the relevant proof here as this notebook is already getting rather long, but we do not want to simply take h as small as possible. We want to minimize the mean square error, which is the sum of the variance and the square of the bias. If we use central diferences, the bias is zero, so we only need to minimize the variance. It can be shown that \n",
    "$h$ should be of the order $n^{1/6}$ to minimize the MSE around the order of $n^{-2/3}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Analysis\n",
    "\n",
    "Let us first begin with some simple analysis. We will construct our standard Monte Carlo set up  to price options. We will choose the following parameters:\n",
    "\n",
    "$S_0 = 1200, r = 0.03, q = 0.015, T = 1, \\sigma = 0.3,$ and $K = 1150$\n",
    "\n",
    "We will simulate at two points in time for simplicity. Once at $t_1 = 0.5$ and another at $T=1$\n",
    "\n",
    "Let us estimate for a European put the Delta, Gamma, and Vega. Since this is a European option, we can compute the analytical values from our Black Scholes functions as well to compare. We will see later however that our estimation methods can work for exotic options, while these analytical computations will fail.\n",
    "\n",
    "We will assume 1 million sample paths. We will also introduce two parameters, delS and delSig, which represent the small increments we use to perform finite differencing to estimate the Greeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytically computed values from the closed form solution of the Black Scholes equation are: \n",
      "delta Call: 0.6243382342789829\n",
      "delta Put: -0.3607737053240797\n",
      "gamma : 0.001029709521832556\n",
      "vega : 444.8345134316643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "## Define Parameters\n",
    "s0 = 1200\n",
    "K = 1150\n",
    "\n",
    "sig = 0.3\n",
    "T = 1\n",
    "#t1 = 0.5\n",
    "r = 0.03\n",
    "q = 0.015\n",
    "#lmbda = 0.9\n",
    "\n",
    "# optimal h: 1e6**(-1/6)\n",
    "# This equals 0.1\n",
    "# We will use this for delta.\n",
    "# For comparison, we will use a smaller delta for the vega\n",
    "# These are the \"h\" values\n",
    "\n",
    "delS = 0.1\n",
    "delSig = 0.001\n",
    "\n",
    "#1 million paths\n",
    "nN = int(1e6)\n",
    "\n",
    "\n",
    "## Analytical BS values for reference\n",
    "\n",
    "d1 = (np.log(s0/K) + (r - q + sig**2/2)*T)/(sig*np.sqrt(T))\n",
    "d2 = d1 - sig*np.sqrt(T)\n",
    "\n",
    "delC =  np.exp(-q*T) * norm.cdf(d1)\n",
    "delP = -np.exp(-q*T) * norm.cdf(-d1)\n",
    "\n",
    "gammaC = np.exp(-q*T)*norm.pdf(d1)/(s0*sig*np.sqrt(T))\n",
    "# gammaP = gammaC\n",
    "\n",
    "vegaC = s0*np.sqrt(T)*np.exp(-q*T)*norm.pdf(d1)\n",
    "# vegaP = vegaC\n",
    "print(\"The analytically computed values from the closed form solution of the Black Scholes equation are: \")\n",
    "print(f\"\"\"delta Call: {delC}\n",
    "delta Put: {delP}\n",
    "gamma : {gammaC}\n",
    "vega : {vegaC}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Random Numbers\n",
    "\n",
    "Before we continue with the code, it is important to explain what common random numbers are and why they are vital here.\n",
    "\n",
    "Common random numbers is (an implicit) variance reduction technique. That is to say, it results in lowered variance by the very nature of keeping the random numbers *common* between the samples generated. However, unlike other variance reduction techniques, it does not introduce any additional statistics or variables. It can be combined with other *explicit* variance reduction techniques as well, if appropriate.\n",
    "\n",
    "Common random numbers is unrelated to the random number sequence generation. Built in generators in standard packages are psuedo-random, but are sufficiently random for our purposes. They have a less uniform dispersion compared to nonrandom sequences used for simulations, such as the Sobol sequence. You can read more about that here: https://en.wikipedia.org/wiki/Sobol_sequence\n",
    "\n",
    "The code below computes the Option's delta. There is a flag present that affects a simple change in an if/else block regarding what random numbers to use. If CRN is true, we use the same random numbers for all 3 paths for central finite difference approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When not using Common Random numbers:\n",
      "\n",
      "      The forward finite difference estimator for the Delta is:\n",
      "            Call: 2.3159\n",
      "            Put: -1.6057\n",
      "      The central finite difference estimator for the Delta is:\n",
      "            Call: 2.2810\n",
      "            Put: -1.7691\n",
      "      The central finite difference estimator for the Gamma is:\n",
      "            0.6972 (same for call and put)\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "## 1. Simple  Simulation and CRN\n",
    "\n",
    "def compute( CRN ):\n",
    "\n",
    "      ## Simulate three times, one for the stock price process, one minus delS, one plus delS\n",
    "      np.random.seed(12345)\n",
    "      z1 = np.random.randn(nN)\n",
    "      z2 = np.random.randn(nN)\n",
    "      z3 = np.random.randn(nN)\n",
    "\n",
    "      if(CRN):\n",
    "            STU  = (s0 + delS)*np.exp((r-q-sig**2/2)*T + sig*np.sqrt(T)*z1)\n",
    "            ST   = s0         *np.exp((r-q-sig**2/2)*T + sig*np.sqrt(T)*z1)\n",
    "            STD  = (s0 - delS)*np.exp((r-q-sig**2/2)*T + sig*np.sqrt(T)*z1)\n",
    "      else:\n",
    "            STU  = (s0 + delS)*np.exp((r-q-sig**2/2)*T + sig*np.sqrt(T)*z1)\n",
    "            ST   = s0         *np.exp((r-q-sig**2/2)*T + sig*np.sqrt(T)*z2)\n",
    "            STD  = (s0 - delS)*np.exp((r-q-sig**2/2)*T + sig*np.sqrt(T)*z3)\n",
    "\n",
    "      #compute payoffs using the central point\n",
    "      tmpC = np.exp(-r*T)*np.maximum(ST-K, 0) \n",
    "      tmpP = np.exp(-r*T)*np.maximum(K-ST, 0)\n",
    "\n",
    "      #compute payoffs using the forward point\n",
    "      tmpUC = np.exp(-r*T)*np.maximum(STU - K,0) #CALL\n",
    "      tmpUP = np.exp(-r*T)*np.maximum(K - STU,0) #PUT\n",
    "\n",
    "      #compute payoffs using the backward point\n",
    "      tmpDC = np.exp(-r*T)*np.maximum(STD - K,0) #CALL\n",
    "      tmpDP = np.exp(-r*T)*np.maximum(K - STD,0) #PUT\n",
    "\n",
    "      #Deltas (Greeks), forward and central estimators\n",
    "\n",
    "      delC_Fwd = np.mean((tmpUC - tmpC))/delS\n",
    "      delC_Central = np.mean((tmpUC - tmpDC))/(2*delS)\n",
    "\n",
    "      delP_Cwd = np.mean((tmpUP - tmpP))/delS\n",
    "      delP_Central = np.mean((tmpUP - tmpDP))/(2*delS)\n",
    "      \n",
    "      gam_Central  = np.mean((tmpUC - 2*tmpC + tmpDC))/(delS**2)\n",
    "\n",
    "      print(f\"\"\"\n",
    "      The forward finite difference estimator for the Delta is:\n",
    "            Call: {delC_Fwd:.4f}\n",
    "            Put: {delP_Cwd:.4f}\n",
    "      The central finite difference estimator for the Delta is:\n",
    "            Call: {delC_Central:.4f}\n",
    "            Put: {delP_Central:.4f}\n",
    "      The central finite difference estimator for the Gamma is:\n",
    "            {gam_Central:.4f} (same for call and put)\n",
    "      \"\"\")\n",
    "\n",
    "print(\"When not using Common Random numbers:\")\n",
    "compute(CRN = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using CRN:\n",
      "\n",
      "      The forward finite difference estimator for the Delta is:\n",
      "            Call: 0.6251\n",
      "            Put: -0.3604\n",
      "      The central finite difference estimator for the Delta is:\n",
      "            Call: 0.6251\n",
      "            Put: -0.3605\n",
      "      The central finite difference estimator for the Gamma is:\n",
      "            0.0011 (same for call and put)\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(\"When using CRN:\")\n",
    "compute(CRN = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from above that the BSM equation yielded an analytical call delta of 0.624 and a Put Delta of -0.361. As we can see, using common random numbers we get results that make sense. Not using them lead to garbage results\n",
    "\n",
    "The moral of the story here is that when doing sensitivity analysis, it is mandatory to use CRN because we need to perform a sensitivity analysis on each of the unique paths that generated the original sample (S not shifted up or down)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pathwise Estimation\n",
    "\n",
    "Pathwise estimation, which is also sometimes referred to as infinitesimal perturbation analysis (IPA), is a smarter method of estimation. Recall our definition at the start of the our finite differences discussion:\n",
    "\n",
    "$\\alpha (\\theta) = \\mathbb{E}[Y(\\theta)]$\n",
    "\n",
    "Pathwise estimation relies on interchanging the order of differentiation and integration to obtain\n",
    "\n",
    "$\\alpha ^\\prime (\\theta) = \\frac{d}{d\\theta}\\mathbb{E}[Y(\\theta)] = \\mathbb{E} \\left[ \\frac{dY(\\theta)}{d\\theta} \\right]$\n",
    "\n",
    "Research has been done regarding when the interchange is valid. In summary, if, with probability 1, $Y$ is a continuous function of $\\theta$, then the interchange is valid.\n",
    "\n",
    "This means, that if we take $Y(\\theta) = e^{-rT}[S(T) - K]^+$, i.e. the payoff of a European call, $Y$ is continuous and so the interchange applies. Remember, the payoff function has a kink at $S_T = K$, but it is continuous (recall the definitions of continuity and limits from calculus if this is confusing). The derivative of this payoff function does not exist at $S_T = K$, thus, this payoff function is continuous but not differentiable.\n",
    "\n",
    "It is important to note, that due to this condition, the pathwise estimation method does not always work. Consider a Digital option whose payoff is $Y = e^{-rT} \\mathbb{I}_{S_T > K}$. This payoff function is *discontinuous* with a discontinuity at $S_T = K$ and so pathwise estimation is not valid, and we can prove this is the case.\n",
    "\n",
    "If we compute $\\frac{dY}{d\\S_0}$ then we know that this value is $0$ everywhere, because the indicator function is a constant value, which means it has no rate of change, **except** for at the point of discontinuity, where the function jumps to a different constant value.\n",
    "\n",
    "Formally, we use the chain rule:\n",
    "\n",
    "$\\frac{dY}{dS_0} = \\frac{dY}{dS_T} \\frac{dS_T}{dS_0}$\n",
    "\n",
    "where $\\frac{dY}{dS_T} = 0 $ if $S_T > K$ or $S_T < K$\n",
    "and $\\frac{dY}{dS_T}$ does not exist if $S_T = K$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$0 = \\mathbb{E}\\left( \\frac{dY}{dS_0} \\right) \\neq \\frac{d}{dS_0} \\mathbb{E} [Y]$\n",
    "\n",
    "Again, the change in $\\mathbb{E}[Y]$ is due to a change in $S_0$ due to the possibility that a change in $S_0$ will cause $S_T$ to cross (or not cross) the barrier $K$. But this change cannot be captured by the pathwise derivative which is zero almost surely.\n",
    "\n",
    "To code this, it's quite simple. Compute the derivative analytically first, then plug in the values into that expression. No additional simulation is needed. For example, the pathwise delta is given by:\n",
    "\n",
    "$\\frac{dY}{dS_0} = \\frac{dY}{dS_T}\\frac{dS_T}{dS_0} = e^{-rT} \\mathbb{I}_{S_T > K} \\frac{S_T}{S_0}$\n",
    "\n",
    "It should be easy to tell that *this function* is not continuous, and thus its derivative does not exist, meaning the gamma cannot be pathwise-estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The pathwise estimator for the Delta is:\n",
      "    Call: 0.6250\n",
      "    Put: -0.3605\n",
      "\n",
      "\n",
      "The pathwise estimator for the Gamma is:\n",
      "    undefined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##pathwise, using CRN.\n",
    "np.random.seed(12345)\n",
    "z1 = np.random.randn(nN)\n",
    "tmp1  =  s0      *np.exp((r-q-sig**2/2)*T)\n",
    "tmp2 = sig*np.sqrt(T)\n",
    "\n",
    "#tmp1 * tmp2\n",
    "s =  tmp1*np.exp(tmp2*z1)\n",
    "#s = s0         *np.exp((r-q-sig**2/2)*T + sig*np.sqrt(T)*z1)\n",
    "dhds0_Call = np.exp(-r*T)*(s>K)* (s)/s0\n",
    "dhds0_Put = np.exp(-r*T)* (K>s)* (-s)/s0\n",
    "delC_pathwise = np.mean(dhds0_Call)\n",
    "delP_pathwise = np.mean(dhds0_Put)\n",
    "\n",
    "gam_pathwise = np.nan\n",
    "gam_pathwise = 'undefined' if np.isnan(gam_pathwise) else gam_pathwise\n",
    "\n",
    "print(f\"\"\"\n",
    "The pathwise estimator for the Delta is:\n",
    "    Call: {delC_pathwise:.4f}\n",
    "    Put: {delP_pathwise:.4f}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"\n",
    "The pathwise estimator for the Gamma is:\n",
    "    {gam_pathwise}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood Ratio Method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood ratio method invovles computing the derivative\n",
    "\n",
    "$\\alpha ^\\prime (\\theta) = \\frac{d}{d\\theta}\\mathbb{E}[Y(\\theta)] $\n",
    "\n",
    "just as in the pathwise estimation method, however we will rely on the probability density function of the parameter in question. That is to say:\n",
    "\n",
    "\n",
    "$\\alpha ^\\prime (\\theta) = \\frac{d}{d\\theta}\\mathbb{E}[Y(\\theta)] = \\frac{d}{d\\theta}\\mathbb{E}_{\\theta}[Y]$\n",
    "\n",
    "The right hand term means we are computing the expectation with respect to $\\theta$. If we assume that $\\theta \\sim g_{\\theta}(x)$, then\n",
    "\n",
    "$\\frac{d}{d\\theta}\\mathbb{E}_{\\theta}[Y] = \\frac{d}{d\\theta} \\int_\\mathbb{{R}^d} f(x)g_{\\theta}(x)dx$\n",
    "\n",
    "Now, since integrals are linear, the differentiation operator can be moved inside:\n",
    "\n",
    "$=  \\int_\\mathbb{{R}^d}  f(x) \\frac{d}{d\\theta} g_{\\theta}(x)dx$\n",
    "\n",
    "Now, we rewrite $\\frac{dg}{d\\theta}$ as $\\dot{g}_{\\theta} (x)$ which gives us:\n",
    "\n",
    "$ \\int_\\mathbb{{R}^d}  f(x)  \\dot{g}_{\\theta} (x) dx$\n",
    "\n",
    "But recall we were originally trying to compute an expectation with respect to ${g}_{\\theta} (x)$. So, we multiply and divide by this quantity to obtain:\n",
    "\n",
    "$ \\int_\\mathbb{{R}^d}  f(x)   \\frac{\\dot{g}_{\\theta}(x)}{g_{\\theta}(x)} g_{\\theta}(x) dx$\n",
    "\n",
    "which can be re-expressed as:\n",
    "\n",
    "$ \\mathbb{E}_{\\theta}  \\left[ f(X) \\frac{\\dot{g}_{\\theta}(X)}{g_{\\theta}(X)} \\right]$\n",
    "\n",
    "Note the change from $x$, the integration variable  to $X$, the random variable.\n",
    "\n",
    "The ratio of $\\dot{g}$ to $g$ is known as the score function. This score function can be computed analytically, if the density is known and differentiable, which it is for the case of options following a GBM. With this, we obtain an unbiased estimator of $\\alpha ^\\prime (\\theta) = \\frac{1}{n} \\sum\\limits_{i=1}^{n} f(X_i) \\frac{\\dot{g_{\\theta}}(X_i)}{g_{\\theta}(X_i)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The LRM estimator for the Delta is:\n",
      "    Call: 0.6262\n",
      "    Put: -0.3597\n",
      "\n",
      "\n",
      "The LRM estimator for the Gamma is:\n",
      "    Call and Put : 0.0010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#s = ST\n",
    "scoreH_delta_C = np.exp(-r*T)*np.maximum(s - K,0)*z1/(s0*sig*np.sqrt(T))\n",
    "delC_likelihood = np.mean(scoreH_delta_C)\n",
    "\n",
    "scoreH_delta_P = np.exp(-r*T)*np.maximum(K - s,0)*z1/(s0*sig*np.sqrt(T))\n",
    "delP_likelihood = np.mean(scoreH_delta_P)\n",
    "\n",
    "scoreH_gamma = (z1**2 - 1)/(s0**2*sig**2*T) - z1/(s0**2*sig*np.sqrt(T))\n",
    "scoreH_gamma *= np.exp(-r*T)*np.maximum(s - K,0)\n",
    "gam_likelihood = np.mean(scoreH_gamma)\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "The LRM estimator for the Delta is:\n",
    "    Call: {delC_likelihood:.4f}\n",
    "    Put: {delP_likelihood:.4f}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"\n",
    "The LRM estimator for the Gamma is:\n",
    "    Call and Put : {gam_likelihood:.4f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we examine Vega. The process can be extended for other greeks as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vega (same for calls and puts)\n",
      "==================\n",
      "Exact: 444.834513\n",
      "W/ CRN: 446.016728\n",
      "W/O CRN: 596.445724\n",
      "Pathwise estimator: 446.018121\n",
      "Likelihood estimator: 447.101050\n"
     ]
    }
   ],
   "source": [
    "z2 = np.random.randn(nN)\n",
    "\n",
    "tmp1U  =  s0 * np.exp((r - q - (sig + delSig)**2/2)*T)\n",
    "tmp1D  =  s0 * np.exp((r - q - (sig - delSig)**2/2)*T)\n",
    "\n",
    "tmp2U = (sig + delSig) * np.sqrt(T)\n",
    "tmp2D = (sig - delSig) * np.sqrt(T)\n",
    "\n",
    "# (1) W/ Common Random Numbers\n",
    "s = tmp1U * np.exp(tmp2U*z1)\n",
    "tmpU = np.exp(-r*T) * np.maximum(s-K,0)\n",
    "\n",
    "s = tmp1D * np.exp(tmp2D*z1)\n",
    "tmpD = np.exp(-r*T) * np.maximum(s-K,0)\n",
    "\n",
    "vega_CRN = np.mean((tmpU - tmpD)/(2*delSig))\n",
    "\n",
    "# (2) W/O Common Random Numbers\n",
    "s = tmp1U * np.exp(tmp2U*z1)\n",
    "tmpU = np.exp(-r*T) * np.maximum(s-K,0)\n",
    "\n",
    "s = tmp1D * np.exp(tmp2D*z2)\n",
    "tmpD = np.exp(-r*T) * np.maximum(s-K,0)\n",
    "\n",
    "vega_tilde = np.mean((tmpU - tmpD)/(2*delSig))\n",
    "\n",
    "# (3) Pathwise Estimator\n",
    "s =  tmp1 * np.exp(tmp2*z1)\n",
    "dhdsig = np.exp(-r*T) * (s>K) * (s/sig) * (np.log(s/s0) - (r - q+sig**2/2)*T)\n",
    "vega_pathwise = np.mean(dhdsig)\n",
    "\n",
    "# (4) Likelihood Ratio\n",
    "\n",
    "#scoreH = exp(-r*T)*np.maximum(s-K,0)*(sig*(sig*T-np.sqrt(T)*z1)-1)/sig\n",
    "scoreH = np.exp(-r*T)*np.maximum(s - K,0)*((z1**2-1)/sig - z1*np.sqrt(T))\n",
    "vega_likelihood = np.mean(scoreH)\n",
    "\n",
    "print('Vega (same for calls and puts)')\n",
    "print('==================')\n",
    "print('Exact: %f' % vegaC)\n",
    "print('W/ CRN: %f' % vega_CRN)\n",
    "print('W/O CRN: %f' % vega_tilde)\n",
    "print('Pathwise estimator: %f' % vega_pathwise)\n",
    "print('Likelihood estimator: %f' % vega_likelihood)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
